{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "5226a95ba6e6ea70ec33bfe1334afdbfdb3d62e3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "import gc\n",
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import butter\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress pandas future warnings, I am using different library versions locally\n",
    "# that do not raise warnings.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "data_dir = '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ca160dc97e710c6ee002b2ff8a4b0c59d7079f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800,000 data points taken over 20 ms\n",
    "# Grid operates at 50hz, 0.02 * 50 = 1, so 800k samples in 20 milliseconds will capture one complete cycle\n",
    "n_samples = 800000\n",
    "\n",
    "# Sample duration is 20 miliseconds\n",
    "sample_duration = 0.02\n",
    "\n",
    "# Sample rate is the number of samples in one second\n",
    "# Sample rate will be 40mhz\n",
    "sample_rate = n_samples * (1 / sample_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(d, axis=None):\n",
    "    \"\"\"\n",
    "    Mean Absolute Deviation\n",
    "    \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(x, low_cutoff=1000, sample_rate=sample_rate):\n",
    "    \"\"\"\n",
    "    From @randxie https://github.com/randxie/Kaggle-VSB-Baseline/blob/master/src/utils/util_signal.py\n",
    "    Modified to work with scipy version 1.1.0 which does not have the fs parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # nyquist frequency is half the sample rate https://en.wikipedia.org/wiki/Nyquist_frequency\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    norm_low_cutoff = low_cutoff / nyquist\n",
    "    \n",
    "    # Fault pattern usually exists in high frequency band. According to literature, the pattern is visible above 10^4 Hz.\n",
    "    # scipy version 1.2.0\n",
    "    #sos = butter(10, low_freq, btype='hp', fs=sample_fs, output='sos')\n",
    "    \n",
    "    # scipy version 1.1.0\n",
    "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = signal.sosfilt(sos, x)\n",
    "\n",
    "    return filtered_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1ac28211bd02087a9239e28ff13e6275a0fc30de"
   },
   "outputs": [],
   "source": [
    "def denoise_signal( x, wavelet='db4', level=1):\n",
    "    \"\"\"\n",
    "    1. Adapted from waveletSmooth function found here:\n",
    "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "    2. Threshold equation and using hard mode in threshold as mentioned\n",
    "    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
    "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decompose to get the wavelet coefficients\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\", level=level)\n",
    "    \n",
    "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "\n",
    "    # Calculte the univeral threshold\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "    \n",
    "    # Reconstruct the signal using the thresholded coefficients\n",
    "    return pywt.waverec( coeff[1:], wavelet, mode='per' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1ac28211bd02087a9239e28ff13e6275a0fc30de"
   },
   "outputs": [],
   "source": [
    "def denoise_signal_2( x, wavelet='db4', level=1):\n",
    "    \"\"\"\n",
    "    1. Adapted from waveletSmooth function found here:\n",
    "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "    2. Threshold equation and using hard mode in threshold as mentioned\n",
    "    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
    "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decompose to get the wavelet coefficients\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\", level=level)\n",
    "    \n",
    "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "\n",
    "    # Calculte the univeral threshold\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "    \n",
    "    # Reconstruct the signal using the thresholded coefficients\n",
    "    return pywt.waverec( coeff[0:], wavelet, mode='per' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corona(x_dn):\n",
    "    index = pd.Series(x_dn).loc[np.abs(x_dn)>0].index\n",
    "    corona_idx = []\n",
    "    for idx in index:\n",
    "        for i in range(1,maxDistance+1):\n",
    "            if idx+i < pd.Series(x_dn).shape[0]:\n",
    "                if x_dn[idx+i]/(x_dn[idx]+1e-04)<-maxHeightRatio:\n",
    "                    x_dn[idx:idx+maxTicksRemoval] = 0\n",
    "                    corona_idx.append(idx)\n",
    "    return x_dn, corona_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(x_df):\n",
    "    for col in tqdm_notebook(range(0, x_df.shape[1], 3)):\n",
    "        X_HP = []\n",
    "        X_DN = []\n",
    "\n",
    "        X_HP.append(high_pass_filter(x_df.iloc[:,col], low_cutoff=10000, sample_rate=sample_rate))\n",
    "        X_HP.append(high_pass_filter(x_df.iloc[:,col+1], low_cutoff=10000, sample_rate=sample_rate))\n",
    "        X_HP.append(high_pass_filter(x_df.iloc[:,col+2], low_cutoff=10000, sample_rate=sample_rate))\n",
    "\n",
    "        X_DN.append(denoise_signal(X_HP[0], wavelet='haar', level=1))\n",
    "        X_DN.append(denoise_signal(X_HP[1], wavelet='haar', level=1))\n",
    "        X_DN.append(denoise_signal(X_HP[2], wavelet='haar', level=1))\n",
    "\n",
    "        X_DN[0], corona_idx = remove_corona(X_DN[0])\n",
    "        X_DN[1], corona_idx = remove_corona(X_DN[1])\n",
    "        X_DN[2], corona_idx = remove_corona(X_DN[2])\n",
    "\n",
    "        total = X_DN[0] + X_DN[1] + X_DN[2]\n",
    "        total = pd.Series(total)\n",
    "        \n",
    "        numpeaks_id[col:col+3] = total[total!=0].count()\n",
    "        numpospeaks_id[col:col+3] = total[total>0].count()\n",
    "        numnegpeaks_id[col:col+3] = total[total<0].count()\n",
    "\n",
    "        meanamp_id[col:col+3] = np.mean(total)\n",
    "        meanamppos_id[col:col+3] = np.mean(total[total<0])\n",
    "        meanampneg_id[col:col+3] = np.mean(total[total>0])\n",
    "\n",
    "        maxamp_id[col:col+3] = np.max(total)\n",
    "        minamp_id[col:col+3] = np.min(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDistance = 10\n",
    "maxHeightRatio = 0.25\n",
    "maxTicksRemoval =500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpeaks_id_test = []\n",
    "numpospeaks_id_test = []\n",
    "numnegpeaks_id_test = []\n",
    "\n",
    "maxamp_id_test = []\n",
    "minamp_id_test = []\n",
    "meanamp_id_test = []\n",
    "\n",
    "meanamppos_id_test = []\n",
    "meanampneg_id_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cdd57cde054e3683d0c470dbc918b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9330eff70e2648fa977122711e9a2a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1f1eee16a642d28513e235cbcdbe97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06b02ed9ec84e80b9d67b9d0890bcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218fa953adf746bca2fc29679af1f1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30785ee03c5a461f92d25db3d2633ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f807ef808745f397060ba9eeef706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fea9a3b7f014d12b38db3b911438003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=779), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(7)):\n",
    "    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i*3000 + j + 8712) for j in range(3000)]).to_pandas()\n",
    "    \n",
    "    numpeaks_id = np.zeros(subset_test.shape[1])\n",
    "    numpospeaks_id = np.zeros(subset_test.shape[1])\n",
    "    numnegpeaks_id = np.zeros(subset_test.shape[1])\n",
    "    maxamp_id = np.zeros(subset_test.shape[1])\n",
    "    minamp_id = np.zeros(subset_test.shape[1])\n",
    "    meanamp_id = np.zeros(subset_test.shape[1])\n",
    "    meanamppos_id = np.zeros(subset_test.shape[1])\n",
    "    meanampneg_id = np.zeros(subset_test.shape[1])\n",
    "    \n",
    "    main(subset_test)\n",
    "    \n",
    "    numpeaks_id_test = np.hstack((numpeaks_id_test, numpeaks_id))\n",
    "    numpospeaks_id_test = np.hstack((numpospeaks_id_test, numpospeaks_id))\n",
    "    numnegpeaks_id_test = np.hstack((numnegpeaks_id_test, numnegpeaks_id))\n",
    "    \n",
    "    maxamp_id_test = np.hstack((maxamp_id_test, maxamp_id))\n",
    "    minamp_id_test = np.hstack((minamp_id_test, minamp_id))\n",
    "    meanamp_id_test = np.hstack((meanamp_id_test, meanamp_id))\n",
    "    \n",
    "    meanamppos_id_test = np.hstack((meanamppos_id_test, meanamppos_id))\n",
    "    meanampneg_id_test = np.hstack((meanampneg_id_test, meanampneg_id))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../features/numpeaks_id_test.npy', numpeaks_id_test)\n",
    "np.save('../features/numpospeaks_id_test.npy', numpospeaks_id_test)\n",
    "np.save('../features/numnegpeaks_id_test.npy', numnegpeaks_id_test)\n",
    "\n",
    "np.save('../features/maxamp_id_test.npy', maxamp_id_test)\n",
    "np.save('../features/minamp_id_test.npy', minamp_id_test)\n",
    "np.save('../features/meanamp_id_test.npy', meanamp_id_test)\n",
    "\n",
    "np.save('../features/meanamppos_id_test.npy', meanamppos_id_test)\n",
    "np.save('../features/meanampneg_id_test.npy', meanampneg_id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         936.0\n",
       "1         936.0\n",
       "2         936.0\n",
       "3           0.0\n",
       "4           0.0\n",
       "5           0.0\n",
       "6           4.0\n",
       "7           4.0\n",
       "8           4.0\n",
       "9          78.0\n",
       "10         78.0\n",
       "11         78.0\n",
       "12         19.0\n",
       "13         19.0\n",
       "14         19.0\n",
       "15          4.0\n",
       "16          4.0\n",
       "17          4.0\n",
       "18        168.0\n",
       "19        168.0\n",
       "20        168.0\n",
       "21          0.0\n",
       "22          0.0\n",
       "23          0.0\n",
       "24         50.0\n",
       "25         50.0\n",
       "26         50.0\n",
       "27         40.0\n",
       "28         40.0\n",
       "29         40.0\n",
       "          ...  \n",
       "20307      40.0\n",
       "20308      40.0\n",
       "20309      40.0\n",
       "20310     430.0\n",
       "20311     430.0\n",
       "20312     430.0\n",
       "20313       0.0\n",
       "20314       0.0\n",
       "20315       0.0\n",
       "20316     126.0\n",
       "20317     126.0\n",
       "20318     126.0\n",
       "20319    1907.0\n",
       "20320    1907.0\n",
       "20321    1907.0\n",
       "20322     430.0\n",
       "20323     430.0\n",
       "20324     430.0\n",
       "20325      65.0\n",
       "20326      65.0\n",
       "20327      65.0\n",
       "20328      45.0\n",
       "20329      45.0\n",
       "20330      45.0\n",
       "20331     855.0\n",
       "20332     855.0\n",
       "20333     855.0\n",
       "20334     165.0\n",
       "20335     165.0\n",
       "20336     165.0\n",
       "Length: 20337, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(numpeaks_id_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
