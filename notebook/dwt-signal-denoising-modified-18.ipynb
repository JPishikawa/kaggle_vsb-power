{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "5226a95ba6e6ea70ec33bfe1334afdbfdb3d62e3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "import gc\n",
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import butter\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress pandas future warnings, I am using different library versions locally\n",
    "# that do not raise warnings.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "data_dir = '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ca160dc97e710c6ee002b2ff8a4b0c59d7079f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800,000 data points taken over 20 ms\n",
    "# Grid operates at 50hz, 0.02 * 50 = 1, so 800k samples in 20 milliseconds will capture one complete cycle\n",
    "n_samples = 800000\n",
    "\n",
    "# Sample duration is 20 miliseconds\n",
    "sample_duration = 0.02\n",
    "\n",
    "# Sample rate is the number of samples in one second\n",
    "# Sample rate will be 40mhz\n",
    "sample_rate = n_samples * (1 / sample_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(d, axis=None):\n",
    "    \"\"\"\n",
    "    Mean Absolute Deviation\n",
    "    \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(x, low_cutoff=1000, sample_rate=sample_rate):\n",
    "    \"\"\"\n",
    "    From @randxie https://github.com/randxie/Kaggle-VSB-Baseline/blob/master/src/utils/util_signal.py\n",
    "    Modified to work with scipy version 1.1.0 which does not have the fs parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # nyquist frequency is half the sample rate https://en.wikipedia.org/wiki/Nyquist_frequency\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    norm_low_cutoff = low_cutoff / nyquist\n",
    "    \n",
    "    # Fault pattern usually exists in high frequency band. According to literature, the pattern is visible above 10^4 Hz.\n",
    "    # scipy version 1.2.0\n",
    "    #sos = butter(10, low_freq, btype='hp', fs=sample_fs, output='sos')\n",
    "    \n",
    "    # scipy version 1.1.0\n",
    "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = signal.sosfilt(sos, x)\n",
    "\n",
    "    return filtered_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1ac28211bd02087a9239e28ff13e6275a0fc30de"
   },
   "outputs": [],
   "source": [
    "def denoise_signal( x, wavelet='db4', level=1):\n",
    "    \"\"\"\n",
    "    1. Adapted from waveletSmooth function found here:\n",
    "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "    2. Threshold equation and using hard mode in threshold as mentioned\n",
    "    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
    "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decompose to get the wavelet coefficients\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\", level=level)\n",
    "    \n",
    "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "\n",
    "    # Calculte the univeral threshold\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "    \n",
    "    # Reconstruct the signal using the thresholded coefficients\n",
    "    return pywt.waverec( coeff[1:], wavelet, mode='per' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1ac28211bd02087a9239e28ff13e6275a0fc30de"
   },
   "outputs": [],
   "source": [
    "def denoise_signal_2( x, wavelet='db4', level=1):\n",
    "    \"\"\"\n",
    "    1. Adapted from waveletSmooth function found here:\n",
    "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "    2. Threshold equation and using hard mode in threshold as mentioned\n",
    "    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
    "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decompose to get the wavelet coefficients\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\", level=level)\n",
    "    \n",
    "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "\n",
    "    # Calculte the univeral threshold\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "    \n",
    "    # Reconstruct the signal using the thresholded coefficients\n",
    "    return pywt.waverec( coeff[0:], wavelet, mode='per' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corona(x_dn):\n",
    "    index = pd.Series(x_dn).loc[np.abs(x_dn)>0].index\n",
    "    corona_idx = []\n",
    "    for idx in index:\n",
    "        for i in range(1,maxDistance+1):\n",
    "            if idx+i < pd.Series(x_dn).shape[0]:\n",
    "                if x_dn[idx+i]/(x_dn[idx]+1e-04)<-maxHeightRatio:\n",
    "                    x_dn[idx:idx+maxTicksRemoval] = 0\n",
    "                    corona_idx.append(idx)\n",
    "    return x_dn, corona_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDistance = 10\n",
    "maxHeightRatio = 0.25\n",
    "maxTicksRemoval =500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train = pq.read_pandas(data_dir + '/train.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdamp_id = np.zeros(subset_train.shape[1])\n",
    "stdamppos_id = np.zeros(subset_train.shape[1])\n",
    "stdampneg_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "meanamppos_id = np.zeros(subset_train.shape[1])\n",
    "meanampneg_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "numpeaksq2_id = np.zeros(subset_train.shape[1])\n",
    "numpospeaksq2_id = np.zeros(subset_train.shape[1])\n",
    "numnegpeaksq2_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "numpeaksq3_id = np.zeros(subset_train.shape[1])\n",
    "numpospeaksq3_id = np.zeros(subset_train.shape[1])\n",
    "numnegpeaksq3_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "numpeaksq4_id = np.zeros(subset_train.shape[1])\n",
    "numpospeaksq4_id = np.zeros(subset_train.shape[1])\n",
    "numnegpeaksq4_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "coefampq2q3_id = np.zeros(subset_train.shape[1])\n",
    "coefampq2q4_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "stdampq2_id = np.zeros(subset_train.shape[1])\n",
    "stdposampq2_id = np.zeros(subset_train.shape[1])\n",
    "stdnegampq2_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "stdampq3_id = np.zeros(subset_train.shape[1])\n",
    "stdposampq3_id = np.zeros(subset_train.shape[1])\n",
    "stdnegampq3_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "stdampq4_id = np.zeros(subset_train.shape[1])\n",
    "stdposampq4_id = np.zeros(subset_train.shape[1])\n",
    "stdnegampq4_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "meanampq2_id = np.zeros(subset_train.shape[1])\n",
    "meanposampq2_id = np.zeros(subset_train.shape[1])\n",
    "meannegampq2_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "meanampq3_id = np.zeros(subset_train.shape[1])\n",
    "meanposampq3_id = np.zeros(subset_train.shape[1])\n",
    "meannegampq3_id = np.zeros(subset_train.shape[1])\n",
    "\n",
    "meanampq4_id = np.zeros(subset_train.shape[1])\n",
    "meanposampq4_id = np.zeros(subset_train.shape[1])\n",
    "meannegampq4_id = np.zeros(subset_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39431023b1d446a8839af70730f0e21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2904), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwademo123/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/cwademo123/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm_notebook(range(0, subset_train.shape[1], 3)):\n",
    "    X_HP = []\n",
    "    X_DN = []\n",
    "    \n",
    "    X_HP.append(high_pass_filter(subset_train.iloc[:,col], low_cutoff=10000, sample_rate=sample_rate))\n",
    "    X_HP.append(high_pass_filter(subset_train.iloc[:,col+1], low_cutoff=10000, sample_rate=sample_rate))\n",
    "    X_HP.append(high_pass_filter(subset_train.iloc[:,col+2], low_cutoff=10000, sample_rate=sample_rate))\n",
    "    \n",
    "    X_DN.append(denoise_signal(X_HP[0], wavelet='haar', level=1))\n",
    "    X_DN.append(denoise_signal(X_HP[1], wavelet='haar', level=1))\n",
    "    X_DN.append(denoise_signal(X_HP[2], wavelet='haar', level=1))\n",
    "    \n",
    "    X_DN[0], corona_idx = remove_corona(X_DN[0])\n",
    "    X_DN[1], corona_idx = remove_corona(X_DN[1])\n",
    "    X_DN[2], corona_idx = remove_corona(X_DN[2])\n",
    "    \n",
    "    total = X_DN[0] + X_DN[1] + X_DN[2]\n",
    "    total = pd.Series(total)\n",
    "      \n",
    "    stdamp_id[col:col+3] = np.std(total)\n",
    "    stdamppos_id[col:col+3] = np.std(total[total<0])\n",
    "    stdampneg_id[col:col+3] = np.std(total[total>0])\n",
    "\n",
    "    meanamppos_id[col:col+3] = np.mean(total[total<0])\n",
    "    meanampneg_id[col:col+3] = np.mean(total[total>0])\n",
    "    \n",
    "    numpeaksq2_id[col:col+3] = total[100000:200000].loc[total!=0].count()\n",
    "    numpospeaksq2_id[col:col+3] = total[100000:200000].loc[total>0].count()\n",
    "    numnegpeaksq2_id[col:col+3] = total[100000:200000].loc[total<0].count()\n",
    "    \n",
    "    numpeaksq3_id[col:col+3] = total[200000:300000].loc[total!=0].count()\n",
    "    numpospeaksq3_id[col:col+3] = total[200000:300000].loc[total>0].count()\n",
    "    numnegpeaksq3_id[col:col+3] = total[200000:300000].loc[total<0].count()\n",
    "    \n",
    "    numpeaksq4_id[col:col+3] = total[300000:400000].loc[total!=0].count()\n",
    "    numpospeaksq4_id[col:col+3] = total[300000:400000].loc[total>0].count()\n",
    "    numnegpeaksq4_id[col:col+3] = total[300000:400000].loc[total<0].count()\n",
    "    \n",
    "    coefampq2q3_id = np.corrcoef(total[100000:200000], total[200000:300000])[0][1]\n",
    "    coefampq2q4_id = np.corrcoef(total[100000:200000], total[300000:400000])[0][1]\n",
    "    \n",
    "    stdampq2_id[col:col+3] = np.std(total[100000:200000].loc[total!=0])\n",
    "    stdposampq2_id[col:col+3] = np.std(total[100000:200000].loc[total>0])\n",
    "    stdnegampq2_id[col:col+3] = np.std(total[100000:200000].loc[total<0])\n",
    "    \n",
    "    stdampq3_id[col:col+3] = np.std(total[200000:300000].loc[total!=0])\n",
    "    stdposampq3_id[col:col+3] = np.std(total[200000:300000].loc[total>0])\n",
    "    stdnegampq3_id[col:col+3] = np.std(total[200000:300000].loc[total<0])\n",
    "    \n",
    "    stdampq4_id[col:col+3] = np.std(total[300000:400000].loc[total!=0])\n",
    "    stdposampq4_id[col:col+3] = np.std(total[300000:400000].loc[total>0])\n",
    "    stdnegampq4_id[col:col+3] = np.std(total[300000:400000].loc[total<0])\n",
    "    \n",
    "    meanampq2_id[col:col+3] = np.mean(total[100000:200000].loc[total!=0])\n",
    "    meanposampq2_id[col:col+3] = np.mean(total[100000:200000].loc[total>0])\n",
    "    meannegampq2_id[col:col+3] = np.mean(total[100000:200000].loc[total<0])\n",
    "    \n",
    "    meanampq3_id[col:col+3] = np.mean(total[200000:300000].loc[total!=0])\n",
    "    meanposampq3_id[col:col+3] = np.mean(total[200000:300000].loc[total>0])\n",
    "    meannegampq3_id[col:col+3] = np.mean(total[200000:300000].loc[total<0])\n",
    "    \n",
    "    meanampq4_id[col:col+3] = np.mean(total[300000:400000].loc[total!=0])\n",
    "    meanposampq4_id[col:col+3] = np.mean(total[300000:400000].loc[total>0])\n",
    "    meannegampq4_id[col:col+3] = np.mean(total[300000:400000].loc[total<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../features/stdamp_id.npy', stdamp_id)\n",
    "np.save('../features/stdamppos_id.npy', stdamppos_id)\n",
    "np.save('../features/stdampneg_id.npy', stdampneg_id )\n",
    "\n",
    "np.save('../features/meanamppos_id.npy', meanamppos_id)\n",
    "np.save('../features/meanampneg_id.npy', meanampneg_id)\n",
    "\n",
    "np.save('../features/numpeaksq2_id.npy', numpeaksq2_id)\n",
    "np.save('../features/numpeaksq3_id.npy', numpeaksq3_id )\n",
    "np.save('../features/numpeaksq4_id.npy', numpeaksq4_id)\n",
    "\n",
    "np.save('../features/numpospeaksq2_id.npy', numpospeaksq2_id)\n",
    "np.save('../features/numpospeaksq3_id.npy', numpospeaksq3_id )\n",
    "np.save('../features/numpospeaksq4_id.npy', numpospeaksq4_id)\n",
    "\n",
    "np.save('../features/numnegpeaksq2_id.npy', numnegpeaksq2_id)\n",
    "np.save('../features/numnegpeaksq3_id.npy', numnegpeaksq3_id )\n",
    "np.save('../features/numnegpeaksq4_id.npy', numnegpeaksq4_id)\n",
    "\n",
    "np.save('../features/coefampq2q3_id.npy', coefampq2q3_id)\n",
    "np.save('../features/coefampq2q4_id.npy', coefampq2q4_id)\n",
    "\n",
    "np.save('../features/stdampq2_id.npy', stdampq2_id)\n",
    "np.save('../features/stdampq3_id.npy', stdampq3_id )\n",
    "np.save('../features/stdampq4_id.npy', stdampq4_id)\n",
    "\n",
    "np.save('../features/stdposampq2_id.npy', stdposampq2_id)\n",
    "np.save('../features/stdposampq3_id.npy', stdposampq3_id )\n",
    "np.save('../features/stdposampq4_id.npy', stdposampq4_id)\n",
    "\n",
    "np.save('../features/stdnegampq2_id.npy', stdnegampq2_id)\n",
    "np.save('../features/stdnegampq3_id.npy', stdnegampq3_id )\n",
    "np.save('../features/stdnegampq4_id.npy', stdnegampq4_id)\n",
    "\n",
    "np.save('../features/meanampq2_id.npy', meanampq2_id)\n",
    "np.save('../features/meanampq3_id.npy', meanampq3_id )\n",
    "np.save('../features/meanampq4_id.npy', meanampq4_id)\n",
    "\n",
    "np.save('../features/meanposampq2_id.npy', meanposampq2_id)\n",
    "np.save('../features/meanposampq3_id.npy', meanposampq3_id )\n",
    "np.save('../features/meanposampq4_id.npy', meanposampq4_id)\n",
    "\n",
    "np.save('../features/meannegampq2_id.npy', meannegampq2_id)\n",
    "np.save('../features/meannegampq3_id.npy', meannegampq3_id )\n",
    "np.save('../features/meannegampq4_id.npy', meannegampq4_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
